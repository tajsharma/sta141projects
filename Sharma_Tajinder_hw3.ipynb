{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STA 141B Assignment 3\n",
    "\n",
    "Due __Nov 10, 2023__ by __11:59pm__. Submit your work by uploading it to Gradescope through Canvas.\n",
    "\n",
    "Please rename this file as __\"LastName_FirstName_hw3\"__ and export it as as pdf-file. \n",
    "\n",
    "The objective of this assignment is acquire data via web APIs.  \n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Provide your solutions in new cells following each exercise description. Create as many new cells as necessary. Use code cells for your Python scripts and Markdown cells for explanatory text or answers to non-coding questions. Answer all textual questions in complete sentences.\n",
    "\n",
    "2. Prioritize code readability. Just as in writing a book, the clarity of each line matters. Adopt the __one-statement-per-line__ rule. If you have a lengthy code statement, consider breaking it into multiple lines for clarity. (Please note: violating the one-statement-per-line rule will result in a one-point deduction for each offending line.)\n",
    "\n",
    "3. To help understand and maintain code, you should always add comments to explain your code. Use the hash symbol (#) to start writing a comment (homework without any comments will automatically receive 0 points).\n",
    "\n",
    "4. Submit your final work as a __.pdf__ file on __Gradescope__. To convert your .ipynb file into one of these formats, navigate to \"File\", select \"Download as\", and then choose either \"PDF via LaTeX\" or \"HTML\". If \"PDF via LaTeX\" does not work for you, export to \"HTML\", and then use Chrome to print the .html file into PDF. Gradescope only accepts PDF files.\n",
    "\n",
    "5. This assignment will be graded on your proficiency in programming. Be sure to demonstrate your abilities and submit your own, correct and readable solutions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "### Problem 1: Delphi’s Epidata API [2 Points]\n",
    "\n",
    "In order to query a public API, it is important to carefully read the documentation. Consider Delphi’s Epidata API, which - amongst others - tracks and provides data about the Covid-19 disease. We are interested in querying from the COVIDcast Epidata API. Query the API directly, do not use the `covidcast` module!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": [
     "exercise"
    ]
   },
   "source": [
    "#### Exercise\n",
    "\n",
    "a) Make three requests, retrieving the signal `smoothed_wcli` and `smoothed_whh_cmnty_cli` from the `fb-survey` datasource as well as the `confirmed_7dav_incidence_prop` signal from the `jhu-csse` on `2022-01-01` for all states. Transform the response to `pandas.DataFrame`. use `conf_jhu.info()` to check the data is correct.\n",
    "\n",
    "b) Next, create a new table with three columns with the signals `smoothed_wcli`, `smoothed_whh_cmnty_cli` and `confirmed_7dav_incidence_prop`. Drop missing values and compute the sample correlation matrix. Show the sample correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56 entries, 0 to 55\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   geo_value            56 non-null     object \n",
      " 1   signal               56 non-null     object \n",
      " 2   source               56 non-null     object \n",
      " 3   geo_type             56 non-null     object \n",
      " 4   time_type            56 non-null     object \n",
      " 5   time_value           56 non-null     int64  \n",
      " 6   direction            0 non-null      object \n",
      " 7   issue                56 non-null     int64  \n",
      " 8   lag                  56 non-null     int64  \n",
      " 9   missing_value        56 non-null     int64  \n",
      " 10  missing_stderr       56 non-null     int64  \n",
      " 11  missing_sample_size  56 non-null     int64  \n",
      " 12  value                56 non-null     float64\n",
      " 13  stderr               0 non-null      object \n",
      " 14  sample_size          0 non-null      object \n",
      "dtypes: float64(1), int64(6), object(8)\n",
      "memory usage: 6.7+ KB\n",
      "          value_x   value_y     value\n",
      "value_x  1.000000  0.788089  0.458741\n",
      "value_y  0.788089  1.000000  0.541672\n",
      "value    0.458741  0.541672  1.000000\n"
     ]
    }
   ],
   "source": [
    "# a)\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def fetch(data_source, signal):\n",
    "    #base url as well as the object to hold our parameters\n",
    "    datasource_url = 'https://api.delphi.cmu.edu/epidata/covidcast/'\n",
    "    our_params = {\n",
    "        'data_source' : data_source,\n",
    "        'signal' : signal,\n",
    "        'time_type': 'day',\n",
    "        'geo_type' : 'state',\n",
    "        'time_values': '20220101',\n",
    "        'geo_value': '*'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(datasource_url, params = our_params)\n",
    "    #if receive a positive response, we return a populated df, else return empy one\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return pd.DataFrame(data['epidata'])\n",
    "    else:\n",
    "        print('there was an errror fetching your data')\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    \n",
    "# Your code here \n",
    "scl_fb = fetch('fb-survey', 'smoothed_wcli')\n",
    "shccl_fb = fetch('fb-survey', 'smoothed_whh_cmnty_cli')\n",
    "conf_jhu = fetch('jhu-csse', 'confirmed_7dav_incidence_prop')\n",
    "\n",
    "conf_jhu.info()\n",
    "\n",
    "# b)\n",
    "#merge smoothed_wcli and smoother_whh as well as a second merge with the rest of the data\n",
    "concat_df =  pd.merge(scl_fb[['geo_value', 'value']], \n",
    "                      shccl_fb[['geo_value', 'value']], \n",
    "                      on = 'geo_value', how = 'outer')\n",
    "\n",
    "combined_df = pd.merge(concat_df, conf_jhu[['geo_value','value']], \n",
    "                       on = 'geo_value', how = 'outer')\n",
    "\n",
    "#drop any null values from the final df\n",
    "combined_df.dropna()\n",
    "\n",
    "final_correlation_matrix = combined_df.corr()\n",
    "\n",
    "print(final_correlation_matrix)\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: University of California Employee Pay [6 Points]\n",
    "\n",
    "As a public organization, the compensations of employees of all institutions of the University of California are freely accessible. These reports cover UC's career faculty and staff employees, as well as part-time, temporary and student employees. It is accessible [here](https://ucannualwage.ucop.edu). Internally, the data requested by the search mask is queried using an undocumented API. We are interested to compare the gross pay to the number of units actually taught. To this end, we use the [UCD registry](https://registrar-apps.ucdavis.edu/courses/search/index.cfm). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hint__: The University of California Employee Pay API returns an object that is not in json format, since it includes single instead of double quotation marks. Instead of the method `.json`, the data can be accessed using the function `json.loads` from the `json` module, after replacing the quotation marks: \n",
    "\n",
    "    result = requests. ... # this is the request\n",
    "    import json\n",
    "    json.loads(result.text.replace(\"\\'\", \"\\\"\")) # this returns a dict\n",
    "    \n",
    "Also, throughout this exercise, we will extracts digits from strings. This can be achieved using the `re` package: \n",
    "\n",
    "    import re\n",
    "    re.findall('\\d+', \"this is a test 12 string with some 23, 0 digits in it!\") # returns ['12', '23', '0']    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "a) Query the wage API to obtain the annual wage data of 2021 of all UC Davis professors. Remove all privaticed names and return a `pandas.DataFrame` with the first name, last name and gross pay, sorted in descending order. Print the first __six__ rows. The first three are: \n",
    "\n",
    "```\n",
    "> wage_table.head(3)\n",
    "\t    FirstName\t  LastName\tPay\n",
    "1124\tGRIFFITH\t   HARSH\t    1197167.0\n",
    "1503\tCHRISTOPHER\tKREULEN\t  1174990.0\n",
    "1136\tBRIAN\t      HAUS\t     926743.0\n",
    "\n",
    "```\n",
    "\n",
    "b) Next, find out how many _units_ each person of this data frame has taught. To reduce effort, only consider the first 100 rows of `wage_table`, but make your code scalable by using `threading`. Query these employees in the [UCD registry](https://registrar-apps.ucdavis.edu/courses/search/index.cfm). If courses were taught, those will be displayed here. For example `KRAMLINGER` and `Fall Quarter 2023` gives six courses. Each has a link with additional information (e.g., `view 50589`). From there, additional information can be accessed. For the instructional purposes, we will retrieve the value of __Units__ from here, for all courses taught. \n",
    "\n",
    "Aggregate the units for all courses taught in all terms in 2021 for the 100 largest entries from a). Create a new data set, `full_table`, that contains these 100 largest entries from a) and the total units. Add another column that calculates the pay per unit and re-sort the vector. Print the first __six__ rows.\n",
    "\n",
    "```\n",
    "> full_table.head(3) \n",
    "\t   FirstName  LastName\tPay\t     Units\tPayPerUnit\n",
    "1749   RICHARD\tMARDER\t  552965.0\t3\t    184321.666667\n",
    "299\tRICHARD\tBOLD\t    532720.0\t5\t    106544.000000\n",
    "1270   SAMUEL\t HWANG  \t 732169.0\t8\t    91521.125000\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year        First_Name Last_Name        Pay\n",
      "2008  2021          GRIFFITH     HARSH  1197167.0\n",
      "1629  2021       CHRISTOPHER   KREULEN  1174990.0\n",
      "1996  2021             BRIAN      HAUS   926743.0\n",
      "2325  2021       CHRISTOPHER     EVANS   912962.0\n",
      "871   2021            ROBERT   RANDALL   909825.0\n",
      "811   2021  ROLANDO FIGUEROA   ROBERTO   901841.0\n"
     ]
    }
   ],
   "source": [
    "# a) \n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "#base url parameter to insert into object\n",
    "base_url = \"https://ucannualwage.ucop.edu/wage/search.action\"\n",
    "prof_data = []    \n",
    "\n",
    "response = requests.get(base_url, params={\n",
    "        \"year\": '2021',\n",
    "        \"location\": \"Davis\",\n",
    "        \"title\": \"PROF\",\n",
    "        \"sidx\": \"EAW_LST_NAM\",\n",
    "        \"Page\": 1,\n",
    "        \"rows\":3200\n",
    "    })\n",
    "\n",
    "# turn parsed data into a proper format\n",
    "parsed_result = json.loads(response.text.replace(\"'\", \"\\\"\"))\n",
    "\n",
    "# extracting data from the parsed_result dictionary, with the key 'rows'\n",
    "prof_rows_data = parsed_result['rows']\n",
    "prof_data.extend(prof_rows_data)\n",
    "\n",
    "#initiate empty prof list to append to\n",
    "prof_list = []\n",
    "#loop to populate the empty array\n",
    "for professor in prof_data:\n",
    "    professor_dict = {\n",
    "        'Year': professor['cell'][1],\n",
    "        'First_Name': professor['cell'][3],\n",
    "        'Last_Name': professor['cell'][4],\n",
    "        'Pay': float(professor['cell'][6])\n",
    "    }\n",
    "    prof_list.append(professor_dict)\n",
    "\n",
    "#arrange the table via pay column values    \n",
    "wage_table = pd.DataFrame(prof_list)\n",
    "wage_table['Pay'] = wage_table['Pay'].astype(float)\n",
    "\n",
    "# now get descending order of total pay\n",
    "wage_table = wage_table.sort_values(by='Pay', ascending=False)\n",
    "\n",
    "#print statement\n",
    "print(wage_table.head(n=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b) \n",
    "\n",
    "import re\n",
    "import lxml.html as lx\n",
    "\n",
    "# Your code here\n",
    "\n",
    "import concurrent.futures, threading\n",
    "\n",
    "# Your code here\n",
    "\n",
    "#full_table.head(n = 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
